import os
import streamlit as st
from io import BytesIO
from fpdf import FPDF
from environs import Env
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_groq import ChatGroq
from langchain.chains import ConversationChain
from groq import Groq   # usado apenas para validar a key
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Preformatted, ListFlowable, ListItem
)
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics, ttfonts
from io import BytesIO
import re, textwrap, html


env = Env()
env.read_env()


GROQ_API_KEY = env.str("GROQ_API_KEY", default=None)
if not GROQ_API_KEY:
    raise ValueError("GROQ_API_KEY nÃ£o encontrado no .env")
_ = Groq(api_key=GROQ_API_KEY)

chat = ChatGroq(temperature=0, model_name="llama3-70b-8192")


prompt = ChatPromptTemplate.from_messages([
    ("system",
     "VocÃª Ã© a UziBot. Especialista em gestÃ£o de produÃ§Ã£o e usinagem. "
     "VocÃª Ã© um assistente de uma plataforma de gestÃ£o de ferramentas de corte"
     "Sempre responda em portuguÃªs tÃ©cnico, usando dados numÃ©ricos em mm ou %, "
     "sem jargÃµes de TI. Se a pergunta for ambÃ­gua, peÃ§a esclarecimentos. "
     "Se nÃ£o souber, responda 'NÃ£o encontrado'."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{text}")
])

memory = ConversationBufferWindowMemory(
    k=10,                  # Ãºltimas 10 mensagens (ajuste se quiser)
    return_messages=True   # precisa ser True por causa do placeholder
)

base_chain = prompt | chat

# â”€â”€ 2. FÃ¡brica de memÃ³rias por sessÃ£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
memories: dict[str, ConversationBufferWindowMemory] = {}

def get_session_history(session_id: str):
    """Usa st.session_state para persistir o histÃ³rico durante toda a conversa."""
    if "chat_memory" not in st.session_state:
        st.session_state.chat_memory = ConversationBufferWindowMemory(
            k=10, return_messages=True
        ).chat_memory
    return st.session_state.chat_memory

chat_chain = RunnableWithMessageHistory(
    base_chain,
    get_session_history,
    input_messages_key="text",
    history_messages_key="history",
)


if "DejaVu" not in pdfmetrics.getRegisteredFontNames():
    pdfmetrics.registerFont(ttfonts.TTFont("DejaVu", "DejaVuSans.ttf"))

# â”€â”€ estilos base â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
styles = getSampleStyleSheet()
base = styles["Normal"]
base.fontName = "DejaVu"
base.fontSize = 11
base.leading = 15

user_style = ParagraphStyle(
    "user", parent=base, textColor=colors.HexColor("#0B5394"), spaceAfter=4
)
assistant_style = ParagraphStyle(
    "assistant", parent=base, textColor=colors.HexColor("#38761D"), spaceAfter=4
)
mono_style = ParagraphStyle(
    "mono", parent=base, fontName="Courier", backColor="#F3F3F3",
    borderColor="#DDDDDD", borderWidth=0.5, borderPadding=4, spaceAfter=6
)

# â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BOLD_RX = re.compile(r"\*\*(.+?)\*\*", flags=re.S)

def to_html(txt: str) -> str:
    """Converte '**negrito**' e preserva quebras de linha."""
    txt = html.escape(txt)               # &, <, >
    txt = BOLD_RX.sub(r"<b>\1</b>", txt)
    return txt.replace("\n", "<br/>")

LIST_RX = re.compile(r"^\s*[\*\-]\s+", flags=re.M)

def split_bullets(chunk: str):
    """Separa texto normal e itens de lista (* item)"""
    parts = LIST_RX.split(chunk)
    heads = LIST_RX.findall(chunk)
    if not heads:     # nenhum bullet
        return None
    items = [p.strip() for p in parts[1:]]  # primeira parte antes do 1Âº bullet Ã© ''
    return items

# â”€â”€ funÃ§Ã£o principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_pdf(messages) -> BytesIO:
    buffer = BytesIO()
    doc = SimpleDocTemplate(
        buffer, pagesize=A4, leftMargin=35, rightMargin=35, topMargin=35, bottomMargin=35
    )

    flow = []
    for msg in messages:
        role_lbl = "UsuÃ¡rio:" if msg["role"] == "user" else "Assistente:"
        role_style = user_style if msg["role"] == "user" else assistant_style
        flow.append(Paragraph(role_lbl, role_style))

        content = msg["content"]

        # â€” trata blocos de cÃ³digo ```
        for i, part in enumerate(re.split(r"```", content)):
            if i % 2:   # bloco de cÃ³digo
                flow.append(Preformatted(part.strip(), mono_style))
                continue

            # â€” trata listas com '*' na parte "normal"
            bullets = split_bullets(part)
            if bullets:
                for it in bullets:
                    bullet_par = "&#8226;&nbsp;" + to_html(it)  # &#8226; = â€¢
                    flow.append(Paragraph(bullet_par, base))
            else:
                plaintext = part.strip()
                if plaintext:
                    flow.append(Paragraph(to_html(plaintext), base))
        flow.append(Spacer(1, 6))

    doc.build(flow)
    buffer.seek(0)
    return buffer

session_id = "streamlit-session"
def container_chat():
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Exibe histÃ³rico apenas para visualizaÃ§Ã£o
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Entrada do usuÃ¡rio
    if user_input := st.chat_input("Pergunte algo ao assistenteâ€¦"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # Streaming de resposta (sem histÃ³rico enviado ao modelo)
        response_container = st.chat_message("assistant")
        response_text      = response_container.empty()

        full_response = ""
        for chunk in chat_chain.stream(
                {"text": user_input},
                config={"configurable": {"session_id": session_id}}
        ):
            full_response += chunk.content
            response_text.markdown(full_response + "â–Œ")

        response_text.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})

def streamlit_visual():
    st.set_page_config(page_title="Assistente de ProduÃ§Ã£o", layout="wide")

    st.header("ğŸ¤– Assistente de ProduÃ§Ã£o â€” Log Z Tech")
    container_chat()

    st.sidebar.title("âš™ï¸ OpÃ§Ãµes")

    if st.sidebar.button("ğŸ—‘ï¸ Limpar chat"):
        st.session_state.messages = []

    if st.session_state.get("messages"):
        pdf_bytes = generate_pdf(st.session_state.messages)
        st.sidebar.download_button(
            label="ğŸ“„ Exportar chat (PDF)",
            data=pdf_bytes,
            file_name="conversa_chatbot_logz.pdf",
            mime="application/pdf",
        )

def main():
    streamlit_visual()

if __name__ == "__main__":
    main()